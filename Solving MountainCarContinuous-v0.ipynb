{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ddpg_agent:0.0.3 at /Users/sam/ddpg_agent/ddpg_agent.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import ddpg_agent, os\n",
    "from ddpg_agent.agent import DDPG\n",
    "from ddpg_agent.visualizations import create_animation\n",
    "\n",
    "print(\"Using ddpg_agent:%s at %s.\"%(\n",
    "    ddpg_agent.__version__, \n",
    "    os.path.dirname(ddpg_agent.__file__)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous action space: (-1.000 to 1.000)\n",
      "Reward range: (-inf, inf)\n",
      "Observation range, dimension 0: (-1.200 to 0.600)\n",
      "Observation range, dimension 1: (-0.070 to 0.070)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "print('Continuous action space: (%.3f to %.3f)'%(env.action_space.low, env.action_space.high))\n",
    "print('Reward range: %s'%(str(env.reward_range)))\n",
    "for i in range(len(env.observation_space.low)):\n",
    "    print('Observation range, dimension %i: (%.3f to %.3f)'%\n",
    "          (i,env.observation_space.low[i], env.observation_space.high[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "states (InputLayer)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_81 (LeakyReLU)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_82 (LeakyReLU)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_83 (LeakyReLU)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "raw_actions (Dense)          (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "actions (Lambda)             (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,137\n",
      "Trainable params: 1,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Critic model summary:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "states (InputLayer)             (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "actions (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 16)           48          states[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 16)           32          actions[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_87 (LeakyReLU)      (None, 16)           0           dense_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_89 (LeakyReLU)      (None, 16)           0           dense_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 32)           544         leaky_re_lu_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_80 (Dense)                (None, 32)           544         leaky_re_lu_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_88 (LeakyReLU)      (None, 32)           0           dense_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_90 (LeakyReLU)      (None, 32)           0           dense_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32)           0           leaky_re_lu_88[0][0]             \n",
      "                                                                 leaky_re_lu_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_91 (LeakyReLU)      (None, 32)           0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32)           128         leaky_re_lu_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "q_values (Dense)                (None, 1)            33          batch_normalization_11[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,329\n",
      "Trainable params: 1,265\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Hyperparameters:\n",
      "{'train_during_episode': True, 'discount_factor': 0.999, 'tau_actor': 0.3, 'tau_critic': 0.1, 'lr_actor': 0.0001, 'lr_critic': 0.005, 'bn_momentum_actor': 0, 'bn_momentum_critic': 0.7, 'ou_mu': 0, 'ou_theta': 0.05, 'ou_sigma': 1, 'activation_fn_actor': 'tanh', 'replay_buffer_size': 10000, 'replay_batch_size': 1024, 'l2_reg_actor': 0.01, 'l2_reg_critic': 0.01, 'relu_alpha_actor': 0.01, 'relu_alpha_critic': 0.01, 'dropout_actor': 0, 'dropout_critic': 0, 'hidden_layer_sizes_actor': [16, 32, 16], 'hidden_layer_sizes_critic': [[16, 32], [16, 32]], 'input_bn_momentum_actor': 0, 'input_bn_momentum_critic': 0, 'activity_l2_reg': 0, 'output_action_regularizer': 0}\n"
     ]
    }
   ],
   "source": [
    "agent = DDPG(env, train_during_episode=True, ou_mu=0, ou_theta=.05, ou_sigma=.25, \n",
    "             discount_factor=.999, replay_buffer_size=10000, replay_batch_size=1024,\n",
    "             tau_actor=.3, tau_critic=.1, \n",
    "             relu_alpha_actor=.01, relu_alpha_critic=.01,\n",
    "             lr_actor=.0001, lr_critic=.005, activation_fn_actor='tanh',\n",
    "             l2_reg_actor=.01, l2_reg_critic=.01, \n",
    "             bn_momentum_actor=0, bn_momentum_critic=.7,\n",
    "             hidden_layer_sizes_actor=[16,32,16], hidden_layer_sizes_critic=[[16,32],[16,32]], )\n",
    "agent.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6 - epsilon: 0.98, memory size: 359, num steps: 79, training score: 77.55, test score: -0.01\n",
      "Episode 7 - epsilon: 0.96, memory size: 457, num steps: 98, training score: 79.04, test score: -0.01\n",
      "Episode 8 - epsilon: 0.94, memory size: 657, num steps: 200, training score: -31.56, test score: -0.00\n",
      "Episode 9 - epsilon: 0.92, memory size: 728, num steps: 71, training score: 91.23, test score: -0.01\n",
      "Episode 10 - epsilon: 0.9, memory size: 839, num steps: 111, training score: 75.84, test score: -0.00\n",
      "Episode 11 - epsilon: 0.88, memory size: 976, num steps: 137, training score: 70.50, test score: -0.01\n",
      "Episode 12 - epsilon: 0.86, memory size: 1060, num steps: 84, training score: 84.21, test score: -0.01\n",
      "Episode 13 - epsilon: 0.84, memory size: 1091, num steps: 31, training score: 91.22, test score: -0.02\n",
      "Episode 14 - epsilon: 0.82, memory size: 1139, num steps: 48, training score: 91.27, test score: -0.61\n",
      "Episode 15 - epsilon: 0.8, memory size: 1161, num steps: 22, training score: 93.43, test score: -1.62\n",
      "Episode 16 - epsilon: 0.78, memory size: 1228, num steps: 67, training score: 87.74, test score: -9.72\n",
      "Episode 17 - epsilon: 0.76, memory size: 1296, num steps: 68, training score: 82.47, test score: -26.03\n",
      "Episode 18 - epsilon: 0.74, memory size: 1359, num steps: 63, training score: 82.11, test score: -46.23\n",
      "Episode 19 - epsilon: 0.72, memory size: 1457, num steps: 98, training score: 79.17, test score: -55.10\n",
      "Episode 20 - epsilon: 0.7, memory size: 1524, num steps: 67, training score: 83.04, test score: 71.67\n",
      "Episode 21 - epsilon: 0.68, memory size: 1580, num steps: 56, training score: 79.14, test score: 87.57\n",
      "Episode 22 - epsilon: 0.66, memory size: 1624, num steps: 44, training score: 91.69, test score: 93.65\n",
      "Episode 23 - epsilon: 0.64, memory size: 1649, num steps: 25, training score: 95.02, test score: 93.60\n",
      "Episode 24 - epsilon: 0.62, memory size: 1668, num steps: 19, training score: 93.43, test score: 92.38\n",
      "Episode 25 - epsilon: 0.6, memory size: 1709, num steps: 41, training score: 92.20, test score: 93.49\n",
      "Episode 26 - epsilon: 0.58, memory size: 1743, num steps: 34, training score: 91.86, test score: 93.14\n",
      "Episode 27 - epsilon: 0.56, memory size: 1761, num steps: 18, training score: 96.90, test score: 95.74\n",
      "Episode 28 - epsilon: 0.54, memory size: 1779, num steps: 18, training score: 93.76, test score: 91.78\n",
      "Episode 29 - epsilon: 0.52, memory size: 1811, num steps: 32, training score: 92.42, test score: 95.36\n",
      "Episode 30 - epsilon: 0.5, memory size: 1839, num steps: 28, training score: 93.60, test score: 90.20\n",
      "Episode 31 - epsilon: 0.48, memory size: 1856, num steps: 17, training score: 95.20, test score: 91.51\n",
      "Episode 32 - epsilon: 0.46, memory size: 1887, num steps: 31, training score: 93.17, test score: 94.99\n",
      "Episode 33 - epsilon: 0.44, memory size: 1917, num steps: 30, training score: 91.27, test score: 95.52\n",
      "Episode 34 - epsilon: 0.42, memory size: 1947, num steps: 30, training score: 92.70, test score: 94.84\n",
      "Episode 35 - epsilon: 0.4, memory size: 1976, num steps: 29, training score: 89.81, test score: 89.94\n"
     ]
    }
   ],
   "source": [
    "agent.train_n_episodes(30, eps=1, eps_decay=1/50, action_repeat=5, \n",
    "                       run_tests=True, gen_q_a_frames_every_n_steps=10, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ffmpeg at '/Users/sam/mlenv/lib/python3.6/site-packages/imageio_ffmpeg/binaries/ffmpeg-osx64-v4.1'.\n",
      "Video saved to training_animation_1561939113.mp4.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"training animation\" controls loop autoplay>\n",
       "                        <source src=\"training_animation_1561939113.mp4\" type=\"video/mp4\" />\n",
       "                     </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_animation(agent, display_mode='video_file', every_n_steps=10, fps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
